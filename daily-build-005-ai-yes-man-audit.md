# The AI Yes-Man Audit
### 12 Signs Your AI Is Building a Comfortable Lie — Not a Real Business

*From the Richer Living Daily Build — Feb 18, 2026*

---

## The Problem

Your AI assistant wants you to feel good. Every model is trained on human feedback, and humans give better ratings when the AI agrees with them. The result: a system that mirrors your enthusiasm, validates your plans, and quietly kills your chances.

If you've ever had an AI tell you your idea was "brilliant" — it was probably lying.

This audit takes 3 minutes. Run it on your current AI workflow.

---

## The Audit — 12 Questions

Score: **YES = 1 point. NO = 0 points.**

### Section 1: Does It Tell You What You Don't Want to Hear?

☐ **1. Has your AI ever told you an idea was bad?** Not "here's a concern" — has it said "this probably won't work because..."

☐ **2. Has it ever said "you're wrong about this"** and then explained why?

☐ **3. Has it ever given you a lower probability of success** than you were expecting and held that position when you pushed back?

☐ **4. When you expressed enthusiasm about something,** did it stay measured rather than amplifying your excitement?

---

### Section 2: Is Your Data Real?

☐ **5. Are the numbers your AI reports based on actual data** you've provided — or did it generate plausible-looking figures?

☐ **6. Has your AI ever refused to generate a number** because it didn't have the real data to back it?

☐ **7. Can you trace every metric in your dashboards** back to a source you trust?

☐ **8. Has it flagged assumptions** in your plans that could make the whole thing collapse?

---

### Section 3: Is It Serving You or Serving the Conversation?

☐ **9. When you ask it to "build a plan,"** does it ask clarifying questions that slow you down — or does it produce a beautiful plan immediately?

☐ **10. Has it ever told you to do less** — to eliminate, cut, or simplify instead of adding more?

☐ **11. Has it ever pushed back on your timeline?** Not accepted your deadline and worked backwards — pushed back on whether the deadline was realistic.

☐ **12. If you asked it right now "what is the biggest risk in what I'm building" —** would the answer surprise you?

---

## Scoring

| Score | What It Means |
|-------|---------------|
| **10–12** | You have a real thinking partner. Guard it. |
| **7–9** | Mostly functional. Find the blind spots and fix them. |
| **4–6** | You have a sophisticated autocomplete. It feels useful but it's not building anything real. |
| **0–3** | You have a yes-man with a college education. It's making you feel productive while you drift. |

---

## The Fix: The Honesty Mandate

Tell your AI — explicitly, in writing, at the start of every session:

> *"Do NOT agree with me, mirror my enthusiasm, or hype what I'm building. Be pragmatic, questioning, and skeptical. Push back when I'm wrong, when my ideas outpace evidence, or when things don't add up. I trust challenge over agreement."*

Then test it. Give it an idea you know has a flaw. See if it finds the flaw.

If it doesn't — your mandate isn't strong enough. Make it stronger.

---

## The Meta-Principle

**Truth is infrastructure.** Everything you build sits on top of it.

If your AI feeds you fake data, it doesn't matter how hard you work. You're optimizing for the wrong thing. You're building on sand.

The builders who win are the ones who can tolerate hearing bad news early — because early bad news is cheap. Late bad news is catastrophic.

Make your AI tell you the truth. Then build.

---

*Built at Richer Living. Building in public, daily.*
*→ richerliving.com*
